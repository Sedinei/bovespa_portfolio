{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be stored in two dataframes:\n",
    "- `df_stocks`: all the stocks\n",
    "- `df_bench`: only the benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import dateutil\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing pandas dataframes previously saved\n",
    "lst_df_path = glob.glob(os.path.join('preprocessed', 'df_*.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessed/df_PETR3.pickle',\n",
       " 'preprocessed/df_JBSS3.pickle',\n",
       " 'preprocessed/df_CIEL3.pickle']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the path and file names\n",
    "lst_df_path[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the ticker that will be used for Benchmarks later\n",
    "lst_df_path.remove('preprocessed/df_BVSP.pickle')\n",
    "lst_df_path.remove('preprocessed/df_USDBRL.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a separed list for the Benchmarks\n",
    "lst_df_path_bench = ['preprocessed/df_BVSP.pickle', 'preprocessed/df_USDBRL.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all stocks into one dataframe\n",
    "lst_df_stocks = []\n",
    "\n",
    "for fname in lst_df_path:\n",
    "    df = pd.read_pickle(fname)\n",
    "    # keeping only Adj Close\n",
    "    df.drop(columns=['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Open',\n",
    "            'Adj High', 'Adj Low'], inplace=True)\n",
    "    ticker = fname.split('/')[1].split('df_')[1].split('.')[0] \n",
    "    df.columns = [ticker]\n",
    "    lst_df_stocks.append(df)\n",
    "    \n",
    "df_stocks = pd.concat(lst_df_stocks, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks = pd.concat(lst_df_stocks, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PETR3', 'JBSS3', 'CIEL3', 'FLRY3', 'ABEV3', 'IGTA3', 'CPFE3', 'VIVT4',\n",
       "       'CSNA3', 'EMBR3', 'VALE3', 'EQTL3', 'B3SA3', 'UGPA3', 'CYRE3', 'ESTC3',\n",
       "       'GOAU4', 'PETR4', 'LREN3', 'PCAR4', 'MRVE3', 'TIMP3', 'ELET6', 'EGIE3',\n",
       "       'LAME4', 'KROT3', 'CMIG4', 'BBDC4', 'BRAP4', 'RENT3', 'ITUB4', 'QUAL3',\n",
       "       'USIM5', 'GGBR4', 'BBSE3', 'ITSA4', 'MRFG3', 'BRFS3', 'MGLU3', 'BRML3',\n",
       "       'RADL3', 'HYPE3', 'MULT3', 'BRKM5', 'BBDC3', 'NATU3', 'ENBR3', 'CCRO3',\n",
       "       'ELET3', 'CPLE6', 'SBSP3', 'FIBR3', 'ECOR3', 'CSAN3', 'WEGE3', 'BBAS3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking column names\n",
    "df_stocks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating the benchmarks into one dataframe\n",
    "lst_df_bench = []\n",
    "\n",
    "for fname in lst_df_path_bench:\n",
    "    df = pd.read_pickle(fname)\n",
    "    # keeping only Adj Close\n",
    "    df.drop(columns=['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Open',\n",
    "            'Adj High', 'Adj Low'], inplace=True)\n",
    "    ticker = fname.split('/')[1].split('df_')[1].split('.')[0] \n",
    "    df.columns = [ticker]\n",
    "    lst_df_bench.append(df)\n",
    "    \n",
    "df_bench = pd.concat(lst_df_bench, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BVSP', 'USDBRL'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bench.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BVSP</th>\n",
       "      <th>USDBRL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>42141.0</td>\n",
       "      <td>3.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>42141.0</td>\n",
       "      <td>3.9491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>42419.0</td>\n",
       "      <td>4.0373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>41773.0</td>\n",
       "      <td>4.0269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>40695.0</td>\n",
       "      <td>4.0199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               BVSP  USDBRL\n",
       "Date                       \n",
       "2016-01-01  42141.0  3.9500\n",
       "2016-01-04  42141.0  3.9491\n",
       "2016-01-05  42419.0  4.0373\n",
       "2016-01-06  41773.0  4.0269\n",
       "2016-01-07  40695.0  4.0199"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bench.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Optimized Portfolio\n",
    "\n",
    "The objective is to compose a portfolio with good performance using only a small number of stocks from the list.\n",
    "\n",
    "For each month a new portfolio will be elaborated based on the Sharpe Ratio from the previous months, and its performance will be compared with three benchmarks:\n",
    "- iBovespa: the official Index of Bovespa (composed of +60 stocks)\n",
    "- Avg. BVSP: the simple average of all available stocks of iBovespa\n",
    "- Dolar: The current value of USD Dolars in Brazilian *Reais*\n",
    "\n",
    "Additional constraints to the Portfolio:\n",
    "- The max weight of a share is 25%\n",
    "- The minimum weight of a share is 2%\n",
    "\n",
    "**Expected results:**\n",
    "- improved performance on the long run\n",
    "- higher volatility than iBovespa, due to small number of stocks composing the portfolio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Jose Portilla's Udemy course [Python for finance and trading algorithm](https://www.udemy.com/python-for-finance-and-trading-algorithms/learn/v4/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to obtain the expected Return, expected Volatity, and Sharpe Ration from the log returns, given the weights\n",
    "def get_ret_vol_sr(weights):\n",
    "    global log_ret\n",
    "    weights = np.array(weights)    \n",
    "    ret = np.sum( log_ret.mean() * weights * 252)\n",
    "    vol = np.sqrt( np.dot(weights.T, np.dot(log_ret.cov()*252, weights)))\n",
    "    sr = ret/vol\n",
    "    return np.array([ret, vol, sr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the actual function to be minimized\n",
    "def neg_sharpe(weights):\n",
    "    return -1.*get_ret_vol_sr(weights)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contraint function\n",
    "def check_sum(weights):\n",
    "    return np.sum(weights) - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contraint function\n",
    "def check_max_weight(weights):\n",
    "    global max_weight\n",
    "    return np.minimum(weights.max(), max_weight) - weights.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contraint function\n",
    "def check_weights(weights):\n",
    "    global max_weight\n",
    "    w1 = np.sum(weights) - 1.\n",
    "    w2 = np.minimum(weights.max(), max_weight) - weights.max()\n",
    "    return np.abs(w1) + np.abs(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constraint tuple\n",
    "#cons = ({'type' : 'eq', 'fun' : check_sum})\n",
    "#cons = ({'type' : 'eq', 'fun' : check_sum}, {'type' : 'eq', 'fun' : check_max_weight}) # did not work\n",
    "cons = ({'type' : 'eq', 'fun' : check_weights}) # using this workaround instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks = df_stocks.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = tuple([(0,1) for i in range(n_stocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_guess = np.ones(n_stocks) / n_stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting prediction parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the start date of the fist prediction (year, month, day)\n",
    "day_start = datetime.datetime(2017,1,1).date()\n",
    "\n",
    "# total number of months to run the prediction\n",
    "n_months_run = 15\n",
    "\n",
    "# training months before current prediction\n",
    "n_months_train = 10\n",
    "\n",
    "# portfolio weights (before re-balancing)\n",
    "max_weight = 0.25  # used in the constraint function\n",
    "min_weight = 0.02  # used in the running prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running monthly prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "delta_month = dateutil.relativedelta.relativedelta(months=+1)\n",
    "delta_day = dateutil.relativedelta.relativedelta(days=+1)\n",
    "\n",
    "valid_start = day_start\n",
    "valid_end = valid_start + delta_month - delta_day\n",
    "\n",
    "train_start = valid_start - n_months_train*delta_month\n",
    "train_end = valid_start - delta_day\n",
    "\n",
    "time = []\n",
    "p = []\n",
    "b1 = []\n",
    "b2 = []\n",
    "b3 = []\n",
    "\n",
    "\n",
    "#\n",
    "for i in range(n_months_run):\n",
    "    \n",
    "    # dataframes\n",
    "    df_train = df_stocks.truncate(before=train_start, after=train_end)\n",
    "    df_valid = df_stocks.truncate(before=valid_start, after=valid_end)\n",
    "    df_valid_bench = df_bench.truncate(before=valid_start, after=valid_end)\n",
    "    \n",
    "    # calculating log returns of the training data\n",
    "    log_ret = np.log( df_train.divide(df_train.shift(1, axis=0), axis=0) ).iloc[2:]\n",
    "    # notice that log_ret is used by the function `get_ret_vol_sr` and, consequently,\n",
    "    # the `neg_sharpe` function    \n",
    "      \n",
    "    \n",
    "    # calculating optimized weights\n",
    "    opt_results = minimize(neg_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "    \n",
    "    weights = opt_results.x\n",
    "    \n",
    "    \n",
    "    # Weight Re-balancing\n",
    "    idx = np.where(opt_results.x>=min_weight)[0]\n",
    "    weights = weights[idx]\n",
    "    weights /= weights.sum()\n",
    "    \n",
    "    labels = log_ret.columns[idx]\n",
    "    \n",
    "    # using the portfolio weights on the validation data\n",
    "    df1 = df_valid[labels]\n",
    "    df1 = df1/df1.iloc[0] # percentage return of the portfolio\n",
    "    df2 = (df1 * weights).sum(axis=1)\n",
    "    df2 = df2/df2.iloc[0] # percentage return of the portfolio\n",
    "    \n",
    "    # percentage return of the benchmarks\n",
    "    df2b = df_valid_bench/df_valid_bench.iloc[0]\n",
    "    \n",
    "    time.append(valid_start.strftime('%Y/%m'))\n",
    "    p.append(df2.iloc[-1])\n",
    "    b1.append(df2b['BVSP'].iloc[-1])\n",
    "    b2.append(df2b['USDBRL'].iloc[-1])\n",
    "    b3.append(df1.mean(axis=1).iloc[-1]) # Simple average of all stocks\n",
    "    \n",
    "    print('\\nStart: {}, Portfolio: {:.2f}, iBovespa: {:.2f}, Dolar: {:.2f}, Avg. : {:.2f}'.format(time[-1], p[-1],\n",
    "                                                                                                 b1[-1], b2[-1], b3[-1]))\n",
    "    \n",
    "    for l,w in zip(labels, weights):\n",
    "        print('  > {} : {:.2f}'.format(l, w))\n",
    "\n",
    "    \n",
    "    # time update for the next loop\n",
    "    valid_start += delta_month\n",
    "    valid_end  = valid_start + delta_month - delta_day\n",
    "    \n",
    "    train_start += delta_month\n",
    "    train_end = valid_start - delta_day    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presenting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Date' : pd.to_datetime(time),\n",
    "    'Portfolio' : p,\n",
    "    'iBovespa' : b1,\n",
    "    'Dolar' : b2,\n",
    "    'Avg. BVSP' : b3}\n",
    "df_results = pd.DataFrame(data=d)\n",
    "df_results.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average - Monthly returns:')\n",
    "df_results.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('std - Monthly returns:')\n",
    "df_results.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_results.plot(style='-o')\n",
    "ax.axhline(y=1.0, color='gray', linestyle='--', lw=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
