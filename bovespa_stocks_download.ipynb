{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baixando séries históricas do *Yahoo! Finance*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neste tutorial apresenta é apresentado:**\n",
    "  - como obter uma lista de ações\n",
    "  - como baixar séries históricas de uma lista de ações\n",
    "  - como salvar os dataframes no formato pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Considerações**\n",
    "  - O  texto descritivo em linguagem `Markdown` está português, uma vez que a *Bovespa* é brasileira\n",
    "  - Os códigos (variáveis e comentários), no entanto, estão em inglês para facilitar na universalização e compartilhamento, já que podem ser úteis para outros mercados de ações\n",
    "  - O `shell-script` descrito abaixo foi executado em ambiente `GNU/Linux`, contudo sua utilização não é essencial, sendo que o mesmo resultado pode ser obtido através de outra forma\n",
    "  - A ferramenta usada para baixar é o `fix_yahoo_finance` que é uma modificação feita a partir do `pandas_datareader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo a lista de ações (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O objetivo desta etapa é apenas obter uma lista de *tickers*. Caso já a tenha, passe a próxima etapa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista de ações da Composição Atual do IBOV\n",
    "\n",
    "Esta etapa obtém a lista de ações que compõem o índice Bovespa atual (2018). Será usada uma sequência de comandos `bash` para extrair a lista da página [Composição Atual do IBOV - Índice Bovespa](https://br.advfn.com/indice/ibovespa), que serão executados a dentro de uma rotina `Python`, que posteriormente irá salvar a lista em disco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Webscrapping*: baixando a lista da página\n",
    "\n",
    "Poderia ser feito usando `BeautifulSoup` e/ou `Scrapy`? Sim. Com `bash` pode não ser muito sofisticado mas é simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bash command line to be exectuted inside python\n",
    "commands = \"\"\"\n",
    "# Baixando o código html da página\n",
    "wget https://br.advfn.com/indice/ibovespa -O  tmp0.tmp\n",
    "\n",
    "\n",
    "# Extraindo as colunas de tickers e nomes\n",
    "cat tmp0.tmp | head -n434 | tail -n80 > tmp1.tmp\n",
    "cat tmp1.tmp | grep 'br.advfn.com' | cut -c1-200 | cut -d. -f3- | cut -d'\"' -f1,3 > tmp2.tmp\n",
    "cat tmp2.tmp | cut -d'/' -f4-6 | sed -e 's./cotacao\"Cotação .,.g' | cut -d',' -f1 | rev | cut -d'-' -f1 | rev  > tmp4.tmp\n",
    "cat tmp2.tmp | cut -d'/' -f4-6 | sed -e 's./cotacao\"Cotação .,.g' | cut -d',' -f2  > tmp5.tmp\n",
    "\n",
    "# Salvando a lista final\n",
    "paste -d, tmp4.tmp tmp5.tmp > lista_ibovespa.csv\n",
    "\n",
    "# Removendo arquivos temporários\n",
    "rm -f tmp*.tmp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = subprocess.Popen(commands, shell=True, stdout=subprocess.PIPE)\n",
    "msg, err = p.communicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modificações adicionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a lista anterior como `numpy.array`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks listed on iBovespa: 64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# ibovespa stock tickers\n",
    "lst_stocks = np.loadtxt('./lista_ibovespa.csv', delimiter=',', dtype=str)\n",
    "print('Number of stocks listed on iBovespa:', len(lst_stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: ABEV3 | Stock name: Ambev S/A ON\n",
      "Ticker: B3SA3 | Stock name: B3 ON\n",
      "Ticker: BBAS3 | Stock name: Banco do Brasil ON\n",
      "Ticker: BBDC3 | Stock name: Bradesco ON\n",
      "Ticker: BBDC4 | Stock name: Bradesco PN\n"
     ]
    }
   ],
   "source": [
    "for ticker, name in lst_stocks[:5]:\n",
    "    print('Ticker: {} | Stock name: {}'.format(ticker, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O *Yahoo! Finance* emprega um sufixo para ações de bolsas fora dos EUA. Para as ações da Bovespa, por exemplo, aplica o sufixo `.SA` no símbolo de cada ação. Ou seja, a ação *ABEV3* da Ambev é referenciada como 'ABEV3.SA'.\n",
    "\n",
    "Referências:\n",
    "  - [Exchanges and data providers on Yahoo Finance](https://help.yahoo.com/kb/SLN2310.html)\n",
    "  - [Yahoo Finance Exchanges And Suffixes](https://sites.google.com/a/stockhistoricaldata.com/stock-historical-data/yahoo-finance-suffixes)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando o sufixo nos simbolos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: ABEV3.SA\n",
      "Ticker: B3SA3.SA\n",
      "Ticker: BBAS3.SA\n",
      "Ticker: BBDC3.SA\n",
      "Ticker: BBDC4.SA\n",
      "Ticker: USIM5.SA\n",
      "Ticker: VALE3.SA\n",
      "Ticker: VIVT4.SA\n",
      "Ticker: VVAR11.SA\n",
      "Ticker: WEGE3.SA\n"
     ]
    }
   ],
   "source": [
    "# ticker symbols with Bovespa's suffix \n",
    "lst_tickers = np.asarray([ '{}.SA'.format(x) for x in lst_stocks[:,0]], dtype=str)\n",
    "\n",
    "# \n",
    "for ticker in lst_tickers[:5]:\n",
    "    print('Ticker: {}'.format(ticker))\n",
    "    \n",
    "for ticker in lst_tickers[-5:]:\n",
    "    print('Ticker: {}'.format(ticker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incorporando BVMF3, Ibovespa e Dólar \n",
    "\n",
    " * Até 2017 a ação *B3 ON* tinha o símbolo *BVMF3* e em 2018 passou a usar o símbolo *B3SA3*. Assim a *BVMF3.SA* será adicionada manualmente à lista de ações a serem baixadas.\n",
    "\n",
    " * O índice Bovespa (*^BVSP*) e a cotação do Dólar em reais (*USDBRL=X*) também serão adicionadas. (Perceba o prefixo '^' e o sufixo '=X' usados.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: VIVT4.SA\n",
      "Ticker: VVAR11.SA\n",
      "Ticker: WEGE3.SA\n",
      "Ticker: ^BVSP\n",
      "Ticker: USDBRL=X\n"
     ]
    }
   ],
   "source": [
    "# adding BVMF3.SA\n",
    "lst_tickers = np.sort(np.concatenate((lst_tickers, ['BVMF3.SA']))) # this stock changed the name to B3SA3 in 2018\n",
    "\n",
    "# adding ^BVSP and USDBRL=X\n",
    "lst_tickers = np.concatenate((lst_tickers, ['^BVSP', 'USDBRL=X'])) # this stock changed the name to B3SA3 in 2018\n",
    "\n",
    "# checking the last ones\n",
    "for ticker in lst_tickers[-5:]:\n",
    "    print('Ticker: {}'.format(ticker))\n",
    "\n",
    "# saving the list\n",
    "np.savetxt('list_tickers_yahoo.txt', lst_tickers, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baixando as séries históricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O API do *Yahoo! Finance* não funciona mais como antes, causando falhas no uso da biblioteca `pandas_datareader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O recente mal funcionamento com algumas APIs é descrito na página de desenvolvimento do [pandas_datareader](https://pydata.github.io/pandas-datareader/devel/whatsnew.html):\n",
    "\n",
    "> Yahoo!, Google Options, Google Quotes and EDGAR have been immediately deprecated.\n",
    "\n",
    "> Immediate deprecation of Yahoo!, Google Options and Quotes and EDGAR. The end points behind these APIs have radically changed and the existing readers require complete rewrites. In the case of most Yahoo! data the endpoints have been removed. PDR would like to restore these features, and pull requests are welcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe porém uma solução temporária para isto, o [fix-yahoo-finance](https://github.com/ranaroussi/fix-yahoo-finance).\n",
    "\n",
    "O `fix_yahoo_finance` não está disponível na distribuição *Anaconda*, mas é possível o instalar a partir do `pip`:\n",
    "```bash\n",
    "$ pip install fix_yahoo_finance --upgrade --no-cache-dir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o *fix_yahoo_finance*\n",
    "\n",
    "\n",
    "Abaixo é definida uma função que utiliza o módulo `fix_yahoo_finance` para baixar séries históricas do API do *Yahoo! Finance*.\n",
    "\n",
    "\n",
    "A função método `download_stocks_from_yahoo` recebe a lista de símbolos, baixa cada elemento da lista como `DataFrame` do *Pandas* e os salva no formato `pickle` na pasta indicada pela variável `output_path`. O nome do arquivo salvo para cada ação da lista é `df_XXXXX.pickle` onde *XXXXX* representa o símbolo da ação em questão, onde os prefixos e sufixos são removidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "#from pandas_datareader import data as pdr\n",
    "import fix_yahoo_finance as yf\n",
    "\n",
    "# See https://github.com/ranaroussi/fix-yahoo-finance/blob/master/README.rst\n",
    "yf.pdr_override() # <== that's all it takes :-)\n",
    "\n",
    "\n",
    "def download_stocks_from_yahoo(tickers, start, end, output_path='', verbose=1):\n",
    "    '''\n",
    "    Downloads stocks from Yahoo! Finance and saves each stock as a Pandas DataFrame object \n",
    "    in the pickle data format: df_XXXXX.pickle, where XXXXX is the ticker of a particular stock.\n",
    "    \n",
    "    Prefixes and suffixes are removed from the output name.    \n",
    "    \n",
    "    \n",
    "    Inputs: \n",
    "    \n",
    "        tickers: list/array of tickers\n",
    "        start/end: datetime.datetime.date objects\n",
    "        output_path: string\n",
    "        \n",
    "    Outputs:\n",
    "        failed: list of the tickers whose download failed\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    failed = []\n",
    "    \n",
    "    # creates the output folder path if it doesnt exist yet\n",
    "    command = 'mkdir -p {}'.format(output_path)\n",
    "    p = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n",
    "    msg, err = p.communicate()    \n",
    "    \n",
    "    \n",
    "    for ticker in tickers:\n",
    "        \n",
    "        ticker = ticker.upper()\n",
    "        \n",
    "        # deleting Yahoo's prefixes and suffixes from the name\n",
    "        stock_name = ticker.replace('^', '')\n",
    "        stock_name = stock_name.split('=')[0]\n",
    "        stock_name = stock_name.replace('.SA', '')\n",
    "        \n",
    "        # setting the full path for the output file\n",
    "        fname_output = os.path.join(output_path,'df_{}.pickle'.format(stock_name))\n",
    "       \n",
    "        try:\n",
    "            if verbose:\n",
    "                print('\\n Attempting to download {} from {} to {}.'.format(ticker, start, end))\n",
    "                \n",
    "            df = yf.download(ticker, start=start, end=end, as_panel=False)\n",
    "               \n",
    "        except:\n",
    "            failed.append(ticker)\n",
    "            print('* Unable to download {}. * \\n'.format(ticker))\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                df.to_pickle(fname_output)\n",
    "                \n",
    "            except:\n",
    "                print('* Error when trying to save on disk {}. * \\n'.format(fname_output))     \n",
    "\n",
    "    return failed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download das ações\n",
    "\n",
    "Serão baixadas as séries históricas das ações do período de *01/01/2016* até a data presente. Os *DataFrames* serao salvos no formato `pickle` no diretório 'raw'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# loading the list of tickers as a np.array\n",
    "tickers = np.loadtxt('list_tickers_yahoo.txt', dtype=str)\n",
    "\n",
    "# setting the start and end dates\n",
    "start = datetime.datetime(2016, 1, 1).date()\n",
    "end = datetime.datetime.today().date()\n",
    "\n",
    "# setting folder name where dataframes will be saved\n",
    "output_path = 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Attempting to download ABEV3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download B3SA3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download BBAS3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download BBDC3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download BBDC4.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download BBSE3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download BRAP4.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download BRFS3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download BRKM5.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download BRML3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download BVMF3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download CCRO3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download CIEL3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download CMIG4.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download CPFE3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download CPLE6.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download CSAN3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download CSNA3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download CYRE3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download ECOR3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download EGIE3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download ELET3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download ELET6.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download EMBR3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download ENBR3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download EQTL3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download ESTC3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download FIBR3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download FLRY3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download GGBR4.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download GOAU4.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download HYPE3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download IGTA3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download ITSA4.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download ITUB4.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download JBSS3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download KLBN11.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "* Unable to download KLBN11.SA. * \n",
      "\n",
      "\n",
      " Attempting to download KROT3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download LAME4.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download LREN3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download MGLU3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download MRFG3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download MRVE3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download MULT3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download NATU3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download PCAR4.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download PETR3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download PETR4.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download QUAL3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download RADL3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download RAIL3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download RENT3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download SANB11.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download SAPR11.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "* Unable to download SAPR11.SA. * \n",
      "\n",
      "\n",
      " Attempting to download SBSP3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download SMLS3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download SUZB3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download TAEE11.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "* Unable to download TAEE11.SA. * \n",
      "\n",
      "\n",
      " Attempting to download TIMP3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download UGPA3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download USIM5.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download VALE3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download VIVT4.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download VVAR11.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "* Unable to download VVAR11.SA. * \n",
      "\n",
      "\n",
      " Attempting to download WEGE3.SA from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download ^BVSP from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n",
      "\n",
      " Attempting to download USDBRL=X from 2016-01-01 to 2018-04-11.\n",
      "[*********************100%***********************]  1 of 1 downloaded\n"
     ]
    }
   ],
   "source": [
    "# downloading list of tickers\n",
    "lst_failed = download_stocks_from_yahoo(tickers[:], start, end, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to download the following stocks:\n",
      "['KLBN11.SA', 'SAPR11.SA', 'TAEE11.SA', 'VVAR11.SA']\n"
     ]
    }
   ],
   "source": [
    "# Checking for errors\n",
    "\n",
    "if len(lst_failed) > 0:\n",
    "    print('Unable to download the following stocks:')\n",
    "    print(lst_failed)\n",
    "    \n",
    "    #print('\\n Trying one more time:')\n",
    "    #lst_failed = download_stocks_from_yahoo(lst_failed, start, end, output_path)\n",
    "\n",
    "else:\n",
    "    print('All tickers downloaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenação da *BVMF3* e *B3SA3* (opcional)\n",
    "\n",
    "Como comentado anteriormente, esta ação mudou de nome em 2018. Neste passo, os `DataFrames` correspondentes a estas ações serão concatenados em um novo que será salvo em disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561, 6) (6, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-20</th>\n",
       "      <td>25.629999</td>\n",
       "      <td>26.08</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>26.059999</td>\n",
       "      <td>26.059999</td>\n",
       "      <td>5479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-21</th>\n",
       "      <td>26.100000</td>\n",
       "      <td>26.43</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>26.219999</td>\n",
       "      <td>26.219999</td>\n",
       "      <td>6146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-22</th>\n",
       "      <td>26.280001</td>\n",
       "      <td>26.49</td>\n",
       "      <td>25.700001</td>\n",
       "      <td>25.980000</td>\n",
       "      <td>25.980000</td>\n",
       "      <td>5902700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>25.750000</td>\n",
       "      <td>26.02</td>\n",
       "      <td>25.420000</td>\n",
       "      <td>25.430000</td>\n",
       "      <td>25.430000</td>\n",
       "      <td>7084500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>25.799999</td>\n",
       "      <td>26.10</td>\n",
       "      <td>25.250000</td>\n",
       "      <td>25.660000</td>\n",
       "      <td>25.660000</td>\n",
       "      <td>5045700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open   High        Low      Close  Adj Close   Volume\n",
       "Date                                                                  \n",
       "2018-03-20  25.629999  26.08  25.600000  26.059999  26.059999  5479100\n",
       "2018-03-21  26.100000  26.43  25.600000  26.219999  26.219999  6146900\n",
       "2018-03-22  26.280001  26.49  25.700001  25.980000  25.980000  5902700\n",
       "2018-03-23  25.750000  26.02  25.420000  25.430000  25.430000  7084500\n",
       "2018-03-26  25.799999  26.10  25.250000  25.660000  25.660000  5045700"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "picklepath = os.path.join(output_path, 'df_{}.pickle')\n",
    "\n",
    "df1 = pd.read_pickle( picklepath.format('BVMF3') )\n",
    "df2 = pd.read_pickle( picklepath.format('B3SA3') )\n",
    "\n",
    "#\n",
    "print(df1.shape, df2.shape)\n",
    "\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561, 6) (6, 6) (567, 6)\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "print(df1.shape, df2.shape, df3.shape)\n",
    "\n",
    "print(df3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.tail() # there are few days missing\n",
    "\n",
    "# re-writing on disk\n",
    "df3.to_pickle(picklepath.format('B3SA3'))\n",
    "\n",
    "# deleting from disk\n",
    "status = os.system('rm -f {}'.format(picklepath.format('BVMF3')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto é tudo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
